# Kaggle Intro to Deep Learning Notes
  
__NB: Parts of these notes are DIRECTLY COPIED from the [Kaggle Intro to Deep Learning Course](https://www.kaggle.com/learn/intro-to-deep-learning), for example definitions etc.__

## A Single Neuron
  
Using __Keras__ and __Tensorflow__ you can:
  
* Create a __fully-connected__ neural network architecture.
* Apply neural nets to classic Machine Learning problems. (E.g. __regression__ and __classification__)
* Train neural nets with __stochastic gradient descent__.
* improve eprformance with __dropout, batch normalisation__, and other techniques.
  
### What is Deep Learning?
  
Examples of where deep learning models have been near or even exceeded human-level performance are tasks such as natural language translation, image recognition, and game playing.
  
__Deep learning__ is an approach to machine learning that is characterised by deep stacks of computations. The depth of this computation is what has enabled deep learning models to "disentangle" complex and hierarchical patterns like those found in the most challenging real-world datasets.
  
The power and scalability of __neural networks__ have helped them to become the defining model of deep learning. Neural networks are made up of neurons, where each neuron individually performs only a simple computation. The power of neural networks comes from the complexity of the connections that these neurons can form.
  
### The Linear Unit
  
The fundamental component of a neural network is the individual neuron. See the diagram below:
  
![Diagram of the linear unit/neuron](/files/linearunit.png)
  
_The image above is taken from the [Kaggle Intro to Deep Learning Course](https://www.kaggle.com/learn/intro-to-deep-learning) all rights reserved to Kaggle and Ryan Holbrook (Data Scientist - Instructor for this course)._
  
The input is `x` which has __weight__ of `w` on its connection to the neuron. If a value flows through this connection, it is multiplied by the connection's weight. (What reaches the neuron is `w * x`). A neural network "learns" by modifying its weights for each neuron.
  
The __bias__ (`b`) is a special kind of weight that doesn't have any input data associated with it (instead the input is written as `1`, as such what reaches the neuron is `b` as `b * 1 = b`). The bias allows the neuron to modify the output independently of its inputs.
  
`y` is the final output of the neuron. To get this output the neuron sums up all the values it receives through its connections. A linear unit/neuron's "activation" is `y = w * x + b` or `y = wx + b`. (This is the equation of a line.)
  
  
Neurons usually act as part of a larger network however, single neuron models are _linear_ models. For example, if you are using a dataset about cereals: you may train a model with `sugars` as an input and `calories` as the output and find that the bias is `b = 90` and the weight is `w = 2.5` meaning the forumla would be `calories = sugars*2.5 + 90`.
  

It is most likely that a dataset would have many more features than just one. We can expand our model to include __multiple inputs__ by adding more input connections to the neuron (one for each additional feature). The output is then found by multiplying each input to its connection weight and adding them all together. (The formula for a multi-input neuron would by ` y = w<sub>0</sub>x<sub>0</sub> + w<sub>1</sub>x<sub>1</sub> + ... + w<sub>n</sub>x<sub>n</sub> + b`). A linear unit with 2 inputs fits a plane, and a unit with more inputs than that will fit a hyperplane.
  
### Linear Units in Keras
  
In Keras you can use the `keras.Sequential` to easily create a model. This creates a neural network as a stack of layers. Models like those in the notes above can be created using a _"dense"_ layer.
  
You can define a linear model that accepts 3 input features (`input_shape=[3]` - this is as a list to allow for more complex datasets) and produces a single output (`units=1`).
  
  
## Deep Neural Networks

It is possible to build neural networks that are capable of learning incredibly complex relationships. The main idea here is __Modularity__. This is where we build up a complex network from simpler functional units - you can combine linear units to model more complex relationships.
  
  
### Layers
  
Neurons are typically organised into __layers__. Linear units that have a common set of inputs come together to form a __dense__ layer.
  
Each layer of  a neural network can be thought of as performing a kind of simple (ish) transformation. With a deep stack of layers, a network can transform its inputs in more and more complex ways. If the neural network is well-trained then each layer is a transformation that gets closer to the solution.
  
A "layer" is a very general thing in Keras. Basically, a layer can be any kind of data transformation. "Many layers, like the convolutional and recurrent layers, transform data through use of neurons and differ primarily in the pattern of connections they form. Others though are used for feature engineering or just simple arithmetic." (Quoted from Kaggle Notes).
  

### The Activation Function
  
2 dense layers on their own and no better than a single dense layer by itself. Dense layers always focus on the idea of lines and planes. Activation functions are _nonlinear_, as such they allow networks to fit curves. An __activation function__ is some function that is applied to each of a layer's outputs/activations. The most common function is the _rectifier_ function `max(0, x)`. 
  
The __rectifier function__ graph has a line with the negative part "rectified" to 0. If you apply this function to the outputs of a neuron it will put a _bend_ in the data. If a rectifier is attached to a linear unit, this is a __rectified linear unit__ or __ReLU__. (It is common to called the rectifier funciton the "ReLU function".) The output of applying a ReLU activation to a linear unit is: `max(0, w * x + b)`
  
### Stacking Dense Layers
 
You can stack layers to get complex data transformations. The layers before the output layer are sometimes called __hidden__, this is because the only output we see is from the final layer. If the final layer is a linear unit (no activation function) then the network is design for a regression task, i.e. trying to predict some arbitrary numeric value. Tasks like classificaiton may require an activation function on the output.
  
We can use the `Sequential` model to connect a list of layers in order from first to last. NB: the first layer receives the input and the last layer produces the output. (See the the tutorial code - it is important to remember to pass the layers together in a list e.g. `[layer1, layer2, layer3, layer4]`). To add an activation function you just add `activation = '(Name of the function e.g. relu)'` as an argument.
  
NB: Using `layers.Dense(units=8), \n layers.Activation('relu')` is the same as `layers.Dense(units=8, activation='relu')`
  
  
## Stochastic Gradient Descent
  
When networks are first created all their weights are set randomly. Neural networks are trained and "learn" using a set of training data. Training a neural network works by adjusting its weights so that it can transform the features into the target. The weights end up representing the relationship between the features and the target. Alongside the training data two things are required:
  
* The "loss function". This measures how good the network's predictions are.
* The "Optimiser". This tells the network how to change its weights.
  
### The Loss Function
  
The __loss function__ measures the disparity between the model's predictions and the target's true value. Different types of ML problems require different loss functions. __Regression__ problems are where the task is to predict some numerical value. One of the most common loss functions for regression problems is the __mean absolute error__ or __MAE__. MAE finds the absolute difference between each prediction (`y_pred`) and the true target (`y_true`): `abs(y_true - y_pred)`. The total MAE loss, is the mean/average of all the individual absolute differences. Other loss functions used for regression problems include the "Mean-Squared Error" (MSE) or the "Huber Losss". All 3 of the loss functions mentioned are available in Keras. The model uses the loss function as a guide for finding the correct values of its weights. I.e. the loss function gives the network its objective. NB: Lower loss is better.
  

### The Optimiser - Stochastic Gradient Descent (SGD)
  
The __optimiser__ is an algorithm that adjusts the weights to minimise the loss. Almost all optimisation algorithms used in deep learning are part of a family called __Stochastic Gradient Descent__. These are iterative algorithms that train a network in steps. 1 step goes as follows:
  
1. Sample a part of the training data, run it through the network to make predictions. (This sample of training data is called a __minibatch__ or sometimes just a "batch")
2. Mesure the loss between the predictions and the true values.
3. Adjust the weights, in whichever direction will make the loss smaller.
    
This is repeated until the loss is acceptable or won't decrease any further.
  
The complete round of training data is called an __epoch__. (The number of epochs you train for is the number of times that the network sees each training example.) The loss gets smaller as the network's weights get closer to their true values.
  
#### Learning Rate and Batch Size
  
The weights are adjusted in small increments rather than in larger steps. The size of theses "shifts" is determined by something called the __learning rate__. NB: the smaller the learning rate the more minibatches a network needs to see before its weights converge on their best values.
  
The learning rate and the size of the minibatches have the largest effect on the process of SGD training. The interaction between the two parameters is usually very subtle and as such the correct choice for these parameters is tricky to establish.
  
__Adam__ is an SGD algorithm which has an __adaptive learning rate__. This makes it suitable for the majority of problems without any parameter tuning as it is basically self tuning. (Adam is a really good general-purpose optimiser).
  
  
You add the loss function and optimiser to the model using the `compile` method. (See tutorial code). The loss function and optimiser are specified with just a string. (These are also accessible through the Keras API, for example if we wanted to tune the parameters).
  
__What's In a Name? (This is directly copied from the Kaggle course for reference.)__
  
The __gradient__ is a vector that tells us in what direction the weights need to go. More precisely, it tells us how to change the weights to make the loss change _fastest_. We call our process gradient __descent__ because it uses the gradient to _descend_ the loss curve towards a minimum. __Stochastic__ means "determined by chance." Our training is _stochastic_ because the minibatches are _random samples_ from the dataset. And that's why it's called SGD!


## Overfitting and Underfitting
  
You can interpret learning curves (The learning curves are the combined plots of the loss on the training set and the validation set) from training a model in order to guide model development. There are kind of two sorts of information in training data: _signal_ and _noise_:
  
* The __signal__ is the data which generalises and as such helps the model make predictions from new data.
* The __noise__ is the data that is _only_ true for the training data and is therefore not useful. The noise consits of the random fluctuations that occur in real-world data, its made up of the incidental, non-informative patterns that may look useful but actually can't help the model make predictions.
  
Models are trained by choosing weights and/or parameters that minimise the loss on a training set. The model's performance is assessed by evaluating it on a new set of data (the validation data). 
  
  
The loss for the training set will decrease when the model learns either signal or noise however, the loss for the validation set will only go down when the model learns signal. When a model learns signal both the training and validation loss curves will decrease however, when the model learns noise a gap is created between the 2 curves - how big the gap is depicts how much noise the model has learnt. The ideal scenario is where a model learns all of the signal and none of the noise however, this is practically impossible. What instead happens is a trade off where the model learns more signal at the cost of learning more noise - as long as this happens in our favour then the validation loss will continue decrease. (WARNING: There is a point beyond which the cost exceeds the benefit and the validation loss begins to rise).
  
* __Underfitting__ occurs when the loss is not as low as possible because the model hasn't learnt enough _signal_.
* __Overfitting__ is when the loss is not as low as possible because the model has learnt too much _noise_.
  
  
### Capacity
  
The capacity of a model refers to the size and complexity of any patterns that it is able to learn. In neural networks, this is primarily determined by how many neurons it has and how they connect to each other. A way to mitigate underfitting is by trying to increase the network's capactiy. Capacity is increased by:
  
* Making the network wider: add more units to the existing layers. (Wider networks find it easier to learn more linear relationships).
* Making the network deeper: add more layers to the model. (Deeper networks find it easier to learn more nonlinear relationships).
  

### Early Stopping
  
__Early stopping__ is the process of stopping/interrupting the training of the network when the validation loss stops decreasing. Once the validation loss starts to rise this can be detected and the weights can be reset to where the minimum validation loss occured. Early stopping makes sure that the model doesn't carry on learning noise and prevents overfitting of the data. This also reduces the likelihood of stopping the training too early (before the network has finished learning the signal). As such, early stopping helps to also prevent underfitting. Simply, the best thing to do is set the number of training epochs to a high number (more than is required), and then early stopping will do the rest of the work.
  
When using Keras, early stopping is added using a __callback__. This is a function that runs every now and again while the network trains. The early stopping callback runs after every epoch. (See tutorial code for syntax etc.)
  
* `min_delta=0.001` specifies the minimum accepted improvement.
* `patience=20` specifies the number of epochs to wait before stopping if there has been no improvement.
* `restore_best_weights=True` specifies that the best model found should be the one used.
  
  
  
## Dropout and Batch Normalisation
  
There are many different kinds of layers which can be added to machine learning models. Layers like __dense layers__ define connections between neurons. Other layers do things like preprocessing or other forms of transformations. Two other types of layers that are commonly used in modern DL architectures are "Dropout" and "Batch Normalisation".
  

### Dropout
  
The __"Dropout layer"__ can help correct overfitting. Overfitting occurs when the network learns fake patterns in the training data, these often rely on specific combinations of weights. (This can be known as a "conspiracy" of weights, the combinations are usually very fragile - i.e. if one of the weights is removed then the pattern fails). To avoid learning these "conspiracies", some fraction of a layer's inputs are randomly _dropped out_, this makes it much harder for the network to learn erroneous patterns - instead the network searches for more general/broad patterns which tend to be stronger.
  
The dropout creates what can be thought of as an "ensemble of networks". This is because the model's predictions are no longer based off one big network, but a collection of smaller networks. This is beneficial for the same reason that random forests as a group of decision trees works well.
  
Dropout is added in Keras using the following syntax: `layers.Dropout(rate=0.3),` this applies a 30% dropout to the layer which follows it.
  

### Batch Normalisation
  
"Batch normalisation" (also known as "batchnorm") helps correct training that is slow or unstable. Neural networks work best when all the input data is on a common scale. (This can be done using things like scikit-learn's `StandardScaler` or `MinMaxScaler`). SGD shifts the weights of a network in proportion to the size of activation that the data produces, therefore data should be scaled before being used for training. NB: Features that produce activations of very different sizes can make training very unstable.
  
Normalising can be done inside the network and it works pretty well. This is done with the __batch normalisation layer__. A batch normalisation layer inspect each batch as it comes in, then normalises the batch with its own mean and standard deviation, and finally puts the data onto a new scale that has 2 trainable rescaling parameters. "Batchnorm" essentially performs a coordinated rescaling of its inputs.
  
Batch normalisation is usually used to help with the optimisation process however it can also sometimes help with the model's prediction performance. Models that use batchnorm tend to need fewer epochs when training. Batchnorm can fix several different problems that cause the training to be unstable and run into issues.
  
See the tutorial code for details on how to include batch normalisation (`layers.BatchNormalization(),`) - it can be used almost everywhere in a network, either after a layer or between a layer and its activation function. If it is used as the first layer of a network then it acts as a form of adapative preprocessor. (This would be replacing something like Scikit-Learn's `StandardScaler`). NB: Performance is usually best if you standardise the data before it is used for training.
  
  
  
## Binary Classification
  
Neural networks can also be applied to other machine learning problems like classification. When using neural networks for classification the only real differences are the loss function used and the types of outputs that we want the last layer to produce.
  
__Binary classification__ problems are those which classify things into one of two classes. In raw data these can be strings such as "Yes" or "No", "Cat" or "Dog", and "Planet" or "Moon" etc. Before using the data the 2 classes are assigned a __class label__: one class will be a `1` and the other class will be a `0`. (This puts the data in a form that the neural network can use).
  
### Accuracy and Cross-Entropy
  
__Accuracy__ is one of the metrics used for measuring the success of a model on a classification problem. Accuracy is the ratio of correct predictions to total predictions as follows: `accuracy = no_correct_predictions / total_predictions`. A perfect model (one that always makes correct predictions) would have an accuracy score of 1.0. Accuracy is a good metric to use when the classes in the dataset occur with roughly the same frequency.
  
NB: accuracy can't be used as a loss function and as such can't be used with SGD - SGD requires a loss function which changes smoothly. Accuracy is a ratio of sums which by definition changes in jumps. Therefore, a different metric needs to be used that can also act as the loss function - this replacement is the _cross-entropy_ function.
  
When modelling classification problems, the measure should be a distance between probabilities. __Cross-entropy__ can be thought of as a measure for the distance between one probability distribution and another. The aim is to have a network to predict the correct class with a probability of `1.0`. The cross-entropy loss is higher the further away the predicted probability is from `1.0`. In summary, cross-entropy is a good metric to use for a classification loss, the other important metrics (e.g. accuracy) usually improve along with it.
  

### Making Probabilities with the Sigmoid Function
  
Both the cross-entropy and accuracy functions need probabilities as inputs (in the range from 0 to 1). The real-value outputs that are produced by a dense layer must be converted into probabilities, in order to do this a different sort of activation function is used: the __sigmoid activation__. The sigmoid function maps real numbers into the interval `[0,1]`. In order to generate the final class prediction, a _threshold_ probability is defined. (This is usually 0.5, so that rounding will give the correct class - the 0.5 threshold is the default for the Keras accuracy metric).
  
* 0-0.499999 etc. will be given the class label of 0.
* 0.5-1 will be given the class label of 1.
  
_See the tutorial code for how to implement all of the above._
  
  
![Certificate for completing the "Intro to Deep Learning" course.](/files/EdwardSleath_Intro_to_DL.png)
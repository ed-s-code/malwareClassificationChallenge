{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# Code to load the data etc.\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Load the data\n","\n","melbourne_file_path = 'data/melb_data.csv' # Set file path of the data.\n","data = pd.read_csv(melbourne_file_path) # Read the data and store in a data frame.\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Select the target\n","y = data.Price\n","\n","# Only use numerical predictors for the predictions:\n","melb_predictors = data.drop(['Price'], axis=1)\n","X = melb_predictors.select_dtypes(exclude=['object'])\n","\n","# Divide data into training and validation subsets (specifies the split size between training and validation data)\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","# Function for comparing different approaches to deal with the missing values:\n","def score_dataset(X_train, X_valid, y_train, y_valid):\n","    model = RandomForestRegressor(n_estimators=10, random_state=0) # Using 10 different trees...\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_valid)\n","    return mean_absolute_error(y_valid, preds)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE from Approach 1 (Drop columns with missing values):\n","183550.22137772635\n"]}],"source":["# Using APPROACH 1 (DROP COLUMNS WITH MISSING VALUES)\n","\n","# Get names of columns with missing values\n","cols_with_missing = [col for col in X_train.columns\n","                     if X_train[col].isnull().any()]\n","\n","# Drop the columns from the training and validation data (Making sure to drop the same columns in both DataFrames)\n","reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n","reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n","\n","print(\"MAE from Approach 1 (Drop columns with missing values):\")\n","print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))\n","\n","# Initial MAE score: (183550.22137772635)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE from Approach 2 (Imputation):\n","178166.46269899711\n"]}],"source":["# Using APPROACH 2 (IMPUTATION)\n","\n","from sklearn.impute import SimpleImputer\n","\n","# Imputation stage:\n","model_imputer = SimpleImputer()\n","imputed_X_train = pd.DataFrame(model_imputer.fit_transform(X_train))\n","imputed_X_valid = pd.DataFrame(model_imputer.transform(X_valid))\n","\n","# Imputation removed column names; put them back\n","imputed_X_train.columns = X_train.columns\n","imputed_X_valid.columns = X_valid.columns\n","\n","print(\"MAE from Approach 2 (Imputation):\")\n","print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n","\n","# Can see that imputation performed better than dropping the columns on this dataset. (178166.46269899711)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE from Approach 3 (An Extension to Imputation):\n","178927.503183954\n"]}],"source":["# Using APPROACH 3 (IMPUTATION+)\n","\n","# Make copies of the data to avoid changing the originals (When imputing)\n","X_train_plus = X_train.copy()\n","X_valid_plus = X_valid.copy()\n","\n","# Create new columns to indicate what will be imputed:\n","for col in cols_with_missing:\n","    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n","    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n","\n","# Imputation stage:\n","my_imputer = SimpleImputer()\n","imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n","imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n","\n","# Replace the columns that had been removed during imputation.\n","imputed_X_train_plus.columns = X_train_plus.columns\n","imputed_X_valid_plus.columns = X_valid_plus.columns\n","\n","print(\"MAE from Approach 3 (An Extension to Imputation):\")\n","print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n","\n","# In this case Imputation+ performed slightly worse than plain Imputation (178927.503183954)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["(10864, 12)\nCar               49\nBuildingArea    5156\nYearBuilt       4307\ndtype: int64\n"]}],"source":["# Outputs some key details about the training data including its shape and the columns which have missing values.\n","\n","# Shape of training data (num_rows, num_columns)\n","print(X_train.shape)\n","\n","# Number of missing values in each column of training data\n","missing_val_count_by_column = (X_train.isnull().sum())\n","print(missing_val_count_by_column[missing_val_count_by_column > 0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d","display_name":"Python 3.9.0 64-bit"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.9.0","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"metadata":{"interpreter":{"hash":"63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"}}},"nbformat":4,"nbformat_minor":4}
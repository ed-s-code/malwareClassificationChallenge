{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import spacy\n","\n","# Load the large model in order to get the vectors\n","\n","nlp = spacy.load('en_core_web_lg')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12, 300)"]},"metadata":{},"execution_count":2}],"source":["# This disable the other spaCy model pipes as they aren't required in this case (This will speed up the code too)\n","\n","text = \"These vectors can be used as features for machine learning models.\"\n","with nlp.disable_pipes():\n","    vectors = np.array([token.vector for token in  nlp(text)])\n","\n","vectors.shape"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5572, 300)"]},"metadata":{},"execution_count":3}],"source":["import pandas as pd\n","\n","# Load the spam.csv dataset:\n","\n","spam = pd.read_csv('data/spam.csv')\n","\n","# With other pipes disabled calculate the document vectors\n","\n","with nlp.disable_pipes():\n","    doc_vectors = np.array([nlp(text).vector for text in spam.text])\n","\n","# Return the \"shape\" of the vectors found\n","\n","doc_vectors.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Use the doc_vectors and split into training and testing data to be used with scikit-learn ML models:\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(doc_vectors, spam.label, test_size=0.1, random_state=1)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 97.312%\n"]}],"source":["# This uses \"Support Vector Machines\" (SVMs) - similar to other scikit-learn models.\n","\n","from sklearn.svm import LinearSVC\n","\n","# Note from tutorial: Set dual=False to speed up training (it also isn't need in this case)\n","\n","svc = LinearSVC(random_state=1, dual=False, max_iter=10000)\n","svc.fit(X_train, y_train)\n","print(f\"Accuracy: {svc.score(X_test, y_test) * 100:.3f}%\", )"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Function to calculate the cosine similarity:\n","\n","def cosine_similarity(a, b):\n","    return a.dot(b)/np.sqrt(a.dot(a) * b.dot(b))\n","    "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7030031"]},"metadata":{},"execution_count":7}],"source":["# Calculating the cosine similarity between 2 documents:\n","# Example text taken from the Kaggle tutorial code.\n","\n","a = nlp(\"REPLY NOW FOR FREE TEA\").vector\n","b = nlp(\"According to legend, Emperor Shen Nung discovered tea when leaves from a wild tree blew into his pot of boiling water.\").vector\n","cosine_similarity(a, b)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d","display_name":"Python 3.9.0 64-bit"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.9.0","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"metadata":{"interpreter":{"hash":"63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"}}},"nbformat":4,"nbformat_minor":4}